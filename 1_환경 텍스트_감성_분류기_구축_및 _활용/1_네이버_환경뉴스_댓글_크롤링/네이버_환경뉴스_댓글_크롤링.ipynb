{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 댓글을 달 빈 리스트를 생성합니다.\n",
    "\n",
    "# 라이브러리를 로드합니다.\n",
    "from bs4 import BeautifulSoup \n",
    "import requests \n",
    "import re \n",
    "import sys \n",
    "import pprint \n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "import time\n",
    "import numpy as np \n",
    "\n",
    "class NaverCommentsCrawler:\n",
    "    \n",
    "    def __init__(self,start_date=None, end_date=None):\n",
    "        self.idx_result_df = pd.DataFrame()\n",
    "        self.filtered_idx_result_df = pd.DataFrame()\n",
    "        self.t_list = []\n",
    "        \n",
    "        input_file_name = '/media/Data/Naver_News/result/indexing.txt'\n",
    "        \n",
    "        # 인덱싱 파일 읽기\n",
    "        self.idx_result_df = pd.read_csv(input_file_name,encoding=\"UTF8\",header=None)\n",
    "        self.idx_result_df.columns = ['date','title','news','content_url_list','file_list']\n",
    "\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "\n",
    "        # 시작날짜를 지정하지 않을경우 20180302\n",
    "        if(self.start_date == None):\n",
    "            self.start_date = '20100101'\n",
    "\n",
    "        # 끝 날짜를 지정하지 않을경우 어제까지 수집\n",
    "        if(self.end_date == None):\n",
    "            yesterday = date.today() - timedelta(1)\n",
    "            self.end_date = str('20191231')\n",
    "            \n",
    "        dt_index = pd.date_range(start=self.start_date, end = self.end_date)\n",
    "        dt_list = dt_index.strftime(\"%Y-%m-%d\").tolist()\n",
    "\n",
    "        idx = list(map(lambda x: x in dt_list, self.idx_result_df['date'].tolist()))\n",
    "\n",
    "        self.filtered_idx_result_df = self.idx_result_df.loc[idx]\n",
    "    \n",
    "    def crawling_comments(self,url):\n",
    "        \n",
    "        List=[] \n",
    "        oid=url.split(\"oid=\")[1].split(\"&\")[0] \n",
    "        aid=url.split(\"aid=\")[1] \n",
    "        page=1     \n",
    "        header = { \n",
    "          \"User-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36\", \n",
    "          \"referer\":url, \n",
    "        } \n",
    "        \n",
    "        while True : \n",
    "            c_url=\"https://apis.naver.com/commentBox/cbox/web_neo_list_jsonp.json?ticket=news&templateId=default_society&pool=cbox5&_callback=jQuery1707138182064460843_1523512042464&lang=ko&country=&objectId=news\"+oid+\"%2C\"+aid+\"&categoryId=&pageSize=20&indexSize=10&groupId=&listType=OBJECT&pageType=more&page=\"+str(page)+\"&refresh=false&sort=FAVORITE\"  \n",
    "            # 파싱하는 단계입니다.\n",
    "            r=requests.get(c_url,headers=header) \n",
    "            cont=BeautifulSoup(r.content,\"html.parser\")     \n",
    "            total_comm=str(cont).split('comment\":')[1].split(\",\")[0] \n",
    "\n",
    "            match=re.findall('\"contents\":([^\\*]*),\"userIdNo\"', str(cont)) \n",
    "            # 댓글을 리스트에 중첩합니다.\n",
    "            List.append(match) \n",
    "            # 한번에 댓글이 20개씩 보이기 때문에 한 페이지씩 몽땅 댓글을 긁어 옵니다.\n",
    "            if int(total_comm) <= ((page) * 20): \n",
    "                break \n",
    "            else :  \n",
    "                page+=1\n",
    "        \n",
    "        if(len(List) == 0):\n",
    "            f = ''\n",
    "            return f\n",
    "        \n",
    "        f = self.flatten(List)      \n",
    "        f = \" @&/&@ \".join(f)\n",
    "        return f\n",
    "\n",
    "    def crawling_all(self):\n",
    "        url_list =  self.filtered_idx_result_df['content_url_list']  \n",
    "        t_list = []\n",
    "        sec = 10\n",
    "        i = 1\n",
    "        \n",
    "        for u in url_list:\n",
    "            if(i % 2000 == 0):\n",
    "                time.sleep(sec)\n",
    "                print(i)\n",
    "            i= i + 1\n",
    "\n",
    "            try:\n",
    "                cc = self.crawling_comments(u)\n",
    "            except:\n",
    "                cc = ''\n",
    "            \n",
    "            t_list.append(cc)\n",
    "            \n",
    "        self.t_list = t_list\n",
    "            \n",
    "    \n",
    "    # 여러 리스트들을 하나로 묶어 주는 함수입니다.\n",
    "    def flatten(self,l): \n",
    "        flatList = [] \n",
    "        for elem in l: \n",
    "          # if an element of a list is a list \n",
    "          # iterate over this list and add elements to flatList  \n",
    "            if type(elem) == list: \n",
    "                for e in elem: \n",
    "                    flatList.append(e) \n",
    "            else: \n",
    "                flatList.append(elem) \n",
    "        return flatList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncc = NaverCommentsCrawler(start_date=\"2020-01-01\",end_date='2020-01-03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncc.crawling_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "ncc.filtered_idx_result_df[\"comments\"] = ncc.t_list \n",
    "#ncc.filtered_idx_result_df = ncc.filtered_idx_result_df[ncc.filtered_idx_result_df[\"comments\"] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>news</th>\n",
       "      <th>content_url_list</th>\n",
       "      <th>file_list</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>380364</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>伊 대통령 신년사 \"기후변화 대응, 더 늦어서는 안 돼\"</td>\n",
       "      <td>연합뉴스</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
       "      <td>./result/20200101_0.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380365</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>[날씨] 중부지방 곳곳 오전에 눈발…미세먼지 '보통'∼'나쁨'</td>\n",
       "      <td>연합뉴스</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
       "      <td>./result/20200101_1.txt</td>\n",
       "      <td>\"국외미세먼지가 아니고  중국발이다.\" @&amp;/&amp;@ \"미세먼지가 아니라 미세중금속이다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380366</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>내일도 영하권 강추위…수도권 눈발에 미세먼지</td>\n",
       "      <td>뉴시스</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
       "      <td>./result/20200101_2.txt</td>\n",
       "      <td>\"왜 너네 기사만 강추위냐?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380367</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>길냥이에게 따뜻한 보금자리를...[김하국의 애니멀세대]</td>\n",
       "      <td>스포츠서울</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
       "      <td>./result/20200101_3.txt</td>\n",
       "      <td>\"너무 가슴아프면서 가슴 따뜻해지는 기사입니다. 가끔 저희 동네에서도 길냥이들을 보...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380368</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>파주서 야생 멧돼지 ASF바이러스 검출…전국 56번째</td>\n",
       "      <td>연합뉴스</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
       "      <td>./result/20200101_4.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380829</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>대전·세종·충남 구름 많고 온화…미세먼지 '나쁨'</td>\n",
       "      <td>연합뉴스</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
       "      <td>./result/20200103_114.txt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380830</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>전국 대부분 미세먼지 '나쁨'…\"추위 주춤하나 일교차 주의\"</td>\n",
       "      <td>연합뉴스</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
       "      <td>./result/20200103_115.txt</td>\n",
       "      <td>\"어제도 온통 잿빛이였다.문죄인 공약이다 미세먼지 시진핑 만나서 해결한다고했는데 이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380831</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>[단독] “4대강 보 처리방안 내달 말까지 결론”</td>\n",
       "      <td>한겨레</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
       "      <td>./result/20200103_116.txt</td>\n",
       "      <td>\"4대강보 해체? 문재인 대통령은 국정파괴범이다. 공수처로 헌법을 유린했고 탈원전으...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380832</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>오늘 수도권 미세먼지 예비저감조치</td>\n",
       "      <td>국민일보</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
       "      <td>./result/20200103_117.txt</td>\n",
       "      <td>\"국민청원 중국발 초미세먼지 청원 글 올려도 지들이 걸러 버려서 아에 올라가질 않는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380833</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>미세먼지 기승에 수도권 첫 예비저감조치…일교차도 커</td>\n",
       "      <td>뉴시스</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
       "      <td>./result/20200103_118.txt</td>\n",
       "      <td>\"국민청원 중국발 초미세먼지 청원 글 올려도 지들이 걸러 버려서 아에 올라가질 않는...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date                               title   news  \\\n",
       "380364  2020-01-01     伊 대통령 신년사 \"기후변화 대응, 더 늦어서는 안 돼\"   연합뉴스   \n",
       "380365  2020-01-01  [날씨] 중부지방 곳곳 오전에 눈발…미세먼지 '보통'∼'나쁨'   연합뉴스   \n",
       "380366  2020-01-01            내일도 영하권 강추위…수도권 눈발에 미세먼지    뉴시스   \n",
       "380367  2020-01-01      길냥이에게 따뜻한 보금자리를...[김하국의 애니멀세대]  스포츠서울   \n",
       "380368  2020-01-01       파주서 야생 멧돼지 ASF바이러스 검출…전국 56번째   연합뉴스   \n",
       "...            ...                                 ...    ...   \n",
       "380829  2020-01-03         대전·세종·충남 구름 많고 온화…미세먼지 '나쁨'   연합뉴스   \n",
       "380830  2020-01-03   전국 대부분 미세먼지 '나쁨'…\"추위 주춤하나 일교차 주의\"   연합뉴스   \n",
       "380831  2020-01-03         [단독] “4대강 보 처리방안 내달 말까지 결론”    한겨레   \n",
       "380832  2020-01-03                  오늘 수도권 미세먼지 예비저감조치   국민일보   \n",
       "380833  2020-01-03        미세먼지 기승에 수도권 첫 예비저감조치…일교차도 커    뉴시스   \n",
       "\n",
       "                                         content_url_list  \\\n",
       "380364  https://news.naver.com/main/read.nhn?mode=LS2D...   \n",
       "380365  https://news.naver.com/main/read.nhn?mode=LS2D...   \n",
       "380366  https://news.naver.com/main/read.nhn?mode=LS2D...   \n",
       "380367  https://news.naver.com/main/read.nhn?mode=LS2D...   \n",
       "380368  https://news.naver.com/main/read.nhn?mode=LS2D...   \n",
       "...                                                   ...   \n",
       "380829  https://news.naver.com/main/read.nhn?mode=LS2D...   \n",
       "380830  https://news.naver.com/main/read.nhn?mode=LS2D...   \n",
       "380831  https://news.naver.com/main/read.nhn?mode=LS2D...   \n",
       "380832  https://news.naver.com/main/read.nhn?mode=LS2D...   \n",
       "380833  https://news.naver.com/main/read.nhn?mode=LS2D...   \n",
       "\n",
       "                        file_list  \\\n",
       "380364    ./result/20200101_0.txt   \n",
       "380365    ./result/20200101_1.txt   \n",
       "380366    ./result/20200101_2.txt   \n",
       "380367    ./result/20200101_3.txt   \n",
       "380368    ./result/20200101_4.txt   \n",
       "...                           ...   \n",
       "380829  ./result/20200103_114.txt   \n",
       "380830  ./result/20200103_115.txt   \n",
       "380831  ./result/20200103_116.txt   \n",
       "380832  ./result/20200103_117.txt   \n",
       "380833  ./result/20200103_118.txt   \n",
       "\n",
       "                                                 comments  \n",
       "380364                                                     \n",
       "380365  \"국외미세먼지가 아니고  중국발이다.\" @&/&@ \"미세먼지가 아니라 미세중금속이다...  \n",
       "380366                                   \"왜 너네 기사만 강추위냐?\"  \n",
       "380367  \"너무 가슴아프면서 가슴 따뜻해지는 기사입니다. 가끔 저희 동네에서도 길냥이들을 보...  \n",
       "380368                                                     \n",
       "...                                                   ...  \n",
       "380829                                                     \n",
       "380830  \"어제도 온통 잿빛이였다.문죄인 공약이다 미세먼지 시진핑 만나서 해결한다고했는데 이...  \n",
       "380831  \"4대강보 해체? 문재인 대통령은 국정파괴범이다. 공수처로 헌법을 유린했고 탈원전으...  \n",
       "380832  \"국민청원 중국발 초미세먼지 청원 글 올려도 지들이 걸러 버려서 아에 올라가질 않는...  \n",
       "380833  \"국민청원 중국발 초미세먼지 청원 글 올려도 지들이 걸러 버려서 아에 올라가질 않는...  \n",
       "\n",
       "[470 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncc.filtered_idx_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/compat/_optional.py:106: UserWarning: Pandas requires version '0.9.8' or newer of 'xlsxwriter' (version '0.7.3' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "ncc.filtered_idx_result_df.to_excel(\"./2020_2020_E.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
